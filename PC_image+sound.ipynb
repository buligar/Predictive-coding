{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d46af-1a48-4478-a9fc-86022291c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать MNIST с сайта Kaggle\n",
    "# https://www.kaggle.com/datasets/aadeshkoirala/mnist-784\n",
    "# Скачать аудио-датасет free-spoken-digit-dataset \n",
    "# git clone https://github.com/Jakobovski/free-spoken-digit-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1297b-03b1-491f-826b-8024d540b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install imagemagick\n",
    "# !pip install matplotlib==3.9.2\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install numpy==1.26.4\n",
    "# !pip install librosa==0.10.2.post1\n",
    "# !pip install brian2==2.7.1\n",
    "# !pip install soundfile==0.12.1\n",
    "# !pip install ipython==8.27.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b9aaf-1567-4b8b-904b-fcdb784798ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "from brian2 import *\n",
    "import librosa\n",
    "import glob\n",
    "import soundfile as sf\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Воспроизведение звуков в jupyter-notebook\n",
    "try:\n",
    "    import IPython.display as ipd\n",
    "    from IPython.display import display\n",
    "    in_notebook = True\n",
    "except ImportError:\n",
    "    in_notebook = False\n",
    "\n",
    "start_scope()\n",
    "\n",
    "# Основные параметры\n",
    "tau = 10*ms\n",
    "dt = 1*ms\n",
    "defaultclock.dt = dt\n",
    "num_samples = 4 \n",
    "eta = 1e-3 * Hz       # Скорость обучения (1/секунду)\n",
    "decay = 1e-2          # Скорость распада (безразмерная)\n",
    "sample_duration_image = 200*ms   # Продолжительность одного образца изображения\n",
    "sample_duration_audio = 500*ms   # Продолжительность одного образца звука\n",
    "\n",
    "# Убедитесь, что оба имеют одинаковое количество временных шагов для синхронизации\n",
    "sample_duration = max(sample_duration_image, sample_duration_audio)\n",
    "num_time_steps_per_sample = int(sample_duration / dt)\n",
    "total_duration = num_samples * sample_duration\n",
    "\n",
    "def load_preprocess_mnist(num_samples):\n",
    "    df = pd.read_csv('mnist_784.csv')\n",
    "    X = df.iloc[:num_samples, 0:784].values / 255.0 # Нормализация [0-1]\n",
    "    return X\n",
    "\n",
    "def load_preprocess_audio(num_samples, target_length=5000):\n",
    "    audio_files = glob.glob('free-spoken-digit-dataset/recordings/*.wav')\n",
    "    selected_files = audio_files[:num_samples]\n",
    "    \n",
    "    X = []\n",
    "    sr_list = []\n",
    "    for file in selected_files:\n",
    "        signal, sr = librosa.load(file, sr=None)\n",
    "        sr_list.append(sr)\n",
    "        \n",
    "        # Обрезка или приведение сигналов к фиксированной длине        \n",
    "        if len(signal) > target_length:\n",
    "            signal = signal[:target_length]\n",
    "        else:\n",
    "            signal = np.pad(signal, (0, target_length - len(signal)), 'constant')\n",
    "        \n",
    "        # Нормализация [0-1]\n",
    "        signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "        X.append(signal)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    # Предполагается, что все частоты дискретизации одинаковы\n",
    "    sr = sr_list[0] if sr_list else 22050  # По умолчанию 22050, если пусто\n",
    "    return X, sr\n",
    "\n",
    "def prepare_input_data(X_image, X_audio, num_time_steps_per_sample):\n",
    "    num_samples = X_image.shape[0]\n",
    "    N_input_image = X_image.shape[1]\n",
    "    N_input_audio = X_audio.shape[1]\n",
    "    \n",
    "    # Инициализация входных массивов\n",
    "    input_image_array = np.zeros((int(total_duration / dt), N_input_image))\n",
    "    input_audio_array = np.zeros((int(total_duration / dt), N_input_audio))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        start_idx = i * num_time_steps_per_sample\n",
    "        end_idx = (i + 1) * num_time_steps_per_sample\n",
    "        input_image_array[start_idx:end_idx, :] = X_image[i]\n",
    "        input_audio_array[start_idx:end_idx, :] = X_audio[i]\n",
    "    \n",
    "    # Создать временные массивы \n",
    "    Image_ext = TimedArray(input_image_array, dt=dt)\n",
    "    Audio_ext = TimedArray(input_audio_array, dt=dt)\n",
    "    \n",
    "    return Image_ext, Audio_ext\n",
    "\n",
    "# Загрузка и предварительная обработка изображений и аудиоданных\n",
    "X_image = load_preprocess_mnist(num_samples=num_samples)\n",
    "X_audio, sr = load_preprocess_audio(num_samples=num_samples, target_length=5000)\n",
    "\n",
    "# Убедитесь, что оба набора данных имеют одинаковое количество образцов.\n",
    "assert X_image.shape[0] == X_audio.shape[0], \"Несоответствие количества сэмплов между изображением и аудиоданными.\"\n",
    "\n",
    "# Подготовка входных данных\n",
    "Image_ext, Audio_ext = prepare_input_data(X_image, X_audio, num_time_steps_per_sample)\n",
    "\n",
    "# Кол-во нейронов в слоях\n",
    "N_input_image = 784\n",
    "N_input_audio = X_audio.shape[1]\n",
    "N_hidden = 100\n",
    "\n",
    "# Инициализация весов\n",
    "w_input_image_hidden_init = np.random.randn(N_input_image * N_hidden) * 0.01\n",
    "w_input_audio_hidden_init = np.random.randn(N_input_audio * N_hidden) * 0.01\n",
    "w_hidden_image_input_init = np.random.randn(N_hidden * N_input_image) * 0.01\n",
    "w_hidden_audio_input_init = np.random.randn(N_hidden * N_input_audio) * 0.01\n",
    "\n",
    "# Создание групп нейронов\n",
    "input_image_neurons = NeuronGroup(N_input_image, '''\n",
    "    dv/dt = (-v + V_error) / tau : 1\n",
    "    V_error = Image_ext(t, i) - v + V_feedback : 1\n",
    "    V_feedback : 1\n",
    "    ''',\n",
    "    threshold='v > 0.5', reset='v = 0', method='euler')\n",
    "\n",
    "input_audio_neurons = NeuronGroup(N_input_audio, '''\n",
    "    dv/dt = (-v + V_error) / tau : 1\n",
    "    V_error = Audio_ext(t, i) - v + V_feedback : 1\n",
    "    V_feedback : 1\n",
    "    ''',\n",
    "    threshold='v > 0.5', reset='v = 0', method='euler')\n",
    "\n",
    "# Группа скрытых нейронов с раздельными входами**\n",
    "hidden_neurons = NeuronGroup(N_hidden, '''\n",
    "    dv/dt = (-v + V_input_image + V_input_audio) / tau : 1\n",
    "    V_input_image : 1\n",
    "    V_input_audio : 1\n",
    "    ''',\n",
    "    threshold='v > 0.5', reset='v = 0', method='euler')\n",
    "\n",
    "# Создание и подключение синапсов от входа изображения к скрытому слою с помощью обучения\n",
    "syn_input_image_hidden = Synapses(input_image_neurons, hidden_neurons, '''\n",
    "    V_input_image_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_input_image_hidden.connect()\n",
    "syn_input_image_hidden.w = w_input_image_hidden_init \n",
    "\n",
    "# Создание и подключение синапсов от аудиовхода к скрытому слою с помощью обучения\n",
    "syn_input_audio_hidden = Synapses(input_audio_neurons, hidden_neurons, '''\n",
    "    V_input_audio_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_input_audio_hidden.connect()\n",
    "syn_input_audio_hidden.w = w_input_audio_hidden_init\n",
    "\n",
    "# Создание и подключение синапсов от скрытого слоя к входу изображения (обратная связь) с помощью обучения\n",
    "syn_hidden_image_input = Synapses(hidden_neurons, input_image_neurons, '''\n",
    "    V_feedback_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_hidden_image_input.connect()\n",
    "syn_hidden_image_input.w = w_hidden_image_input_init\n",
    "\n",
    "# Создание и подключение синапсов от скрытого слоя к аудиовходу (обратная связь) с помощью обучения\n",
    "syn_hidden_audio_input = Synapses(hidden_neurons, input_audio_neurons, '''\n",
    "    V_feedback_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_hidden_audio_input.connect()\n",
    "syn_hidden_audio_input.w = w_hidden_audio_input_init\n",
    "\n",
    "# Мониторинг мембранных потенциалов\n",
    "mon_hidden = StateMonitor(hidden_neurons, 'v', record=True)\n",
    "mon_input_image = StateMonitor(input_image_neurons, 'v', record=True)\n",
    "mon_input_audio = StateMonitor(input_audio_neurons, 'v', record=True)\n",
    "\n",
    "# Мониторинг спайков\n",
    "spikes_input_image = SpikeMonitor(input_image_neurons)\n",
    "spikes_input_audio = SpikeMonitor(input_audio_neurons)\n",
    "spikes_hidden = SpikeMonitor(hidden_neurons)\n",
    "\n",
    "print(\"Выполнение симуляции...\")\n",
    "run(total_duration) # Запуск симуляции\n",
    "print(\"Симуляция завершена\")\n",
    "\n",
    "# Функция для анимации восстановления изображения\n",
    "def animate_reconstruction_image(sample_index):\n",
    "    # Получение временных индексов для образца\n",
    "    start_time = sample_index * sample_duration\n",
    "    end_time = (sample_index + 1) * sample_duration\n",
    "    start_idx = int(start_time / dt)\n",
    "    end_idx = int(end_time / dt)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.axis('off')\n",
    "    ims = []\n",
    "    \n",
    "    for t in range(start_idx, end_idx):\n",
    "        reconstructed_img = mon_input_image.v[:, t]\n",
    "        im = plt.imshow(reconstructed_img.reshape(28,28), cmap='gray', animated=True)\n",
    "        ims.append([im])\n",
    "    \n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True, repeat_delay=1000)\n",
    "    ani.save(f'reconstruct_image{sample_index}.gif', writer='pillow', fps=20)\n",
    "    plt.title(f'Реконструкция образца изображения {sample_index} по времени')\n",
    "    plt.close(fig)  # Закрыть фигуру, чтобы избежать дополнительного вывода\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "\n",
    "# Функция для анимирования реконструкции звука\n",
    "def animate_reconstruction_audio(sample_index):\n",
    "    start_time = sample_index * sample_duration\n",
    "    end_time = (sample_index + 1) * sample_duration\n",
    "    start_idx = int(start_time / dt)\n",
    "    end_idx = int(end_time / dt)\n",
    "    \n",
    "    # Реконструкция аудиосигнала путем усреднения активности скрытых нейронов\n",
    "    reconstructed_signal = mon_input_audio.v[:, start_idx:end_idx].mean(axis=1)\n",
    "    original_signal = X_audio[sample_index]\n",
    "    \n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(original_signal, label='Original Signal')\n",
    "    plt.plot(reconstructed_signal, label='Reconstructed Signal')\n",
    "    plt.legend()\n",
    "    plt.title(f'Реконструкция аудиообразца {sample_index}')\n",
    "    plt.xlabel('Время')\n",
    "    plt.ylabel('Амплитуда')\n",
    "    plt.show()\n",
    "    \n",
    "    # Сохранить аудиосигналы\n",
    "    sf.write(f'original_signal_sample{sample_index}.wav', original_signal, sr)\n",
    "    sf.write(f'reconstructed_signal_sample{sample_index}.wav', reconstructed_signal, sr)\n",
    "    \n",
    "    # Воспроизведение звука (если в ноутбуке)\n",
    "    if in_notebook:\n",
    "        print(\"Оригинальный сигнал:\")\n",
    "        display(ipd.Audio(original_signal, rate=sr))\n",
    "        print(\"Реконструированный сигнал:\")\n",
    "        display(ipd.Audio(reconstructed_signal, rate=sr))\n",
    "    else:\n",
    "        print(f\"Аудиофайлы, сохраненные как 'original_signal_sample{sample_index}.wav' and 'reconstructed_signal_sample{sample_index}.wav'.\")\n",
    "\n",
    "# Функция для построения графика мембранных потенциалов со смещением\n",
    "def plot_membrane_potentials_with_offset(state_monitor, layer_name, step=10):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    neuron_indices = range(0, len(state_monitor.v), step)\n",
    "    offset = 0\n",
    "    for i in neuron_indices:\n",
    "        plt.plot(state_monitor.t/ms, state_monitor.v[i] + offset, label=f'Neuron {i}')\n",
    "        offset += 1.0\n",
    "    plt.title(f'Мембранный потенциал в {layer_name} (Каждый {step} нейрон со смещением)')\n",
    "    plt.xlabel('Время (мсек)')\n",
    "    plt.ylabel('Мембранный потенциал + смещение')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Функция для построения графика спайков\n",
    "def plot_spikes(spike_monitor, layer_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(spike_monitor.t/ms, spike_monitor.i, '|')\n",
    "    plt.title(f'Спайковая активность в {layer_name}')\n",
    "    plt.xlabel('Время (мсек)')\n",
    "    plt.ylabel('Индекс нейрона')\n",
    "    plt.show()\n",
    "\n",
    "for idx in range(num_samples):\n",
    "    print(f'\\nАнимационная реконструкция для образца изображения {idx}')\n",
    "    animate_reconstruction_image(idx)\n",
    "    print(f'\\nАнимационная реконструкция для аудиосэмпла {idx}')\n",
    "    animate_reconstruction_audio(idx)\n",
    "\n",
    "\n",
    "# plot_membrane_potentials_with_offset(mon_input_image, 'Входний слой с изображениями', step=100)\n",
    "# plot_membrane_potentials_with_offset(mon_input_audio, 'Входной аудиовход', step=500)\n",
    "# plot_membrane_potentials_with_offset(mon_hidden, 'Скрытый слой', step=10)\n",
    "\n",
    "plot_spikes(spikes_input_image, 'Входний слой с изображениями')\n",
    "plot_spikes(spikes_input_audio, 'Входной аудиовход')\n",
    "plot_spikes(spikes_hidden, 'Скрытый слой')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8741f79-6ca9-49f2-b7ce-28f168c08017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
