{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d46af-1a48-4478-a9fc-86022291c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Скачать MNIST с сайта Kaggle\n",
    "# https://www.kaggle.com/datasets/aadeshkoirala/mnist-784\n",
    "# Скачать аудио-датасет free-spoken-digit-dataset \n",
    "# git clone https://github.com/Jakobovski/free-spoken-digit-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1297b-03b1-491f-826b-8024d540b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install imagemagick\n",
    "# !pip install matplotlib==3.9.2\n",
    "# !pip install pandas==2.2.2\n",
    "# !pip install numpy==1.26.4\n",
    "# !pip install librosa==0.10.2.post1\n",
    "# !pip install brian2==2.7.1\n",
    "# !pip install soundfile==0.12.1\n",
    "# !pip install ipython==8.27.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29764376-c0fc-47e8-86cd-42b532a21fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "from brian2 import *\n",
    "import librosa\n",
    "import glob\n",
    "import soundfile as sf\n",
    "from IPython.display import HTML, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from brian2 import prefs\n",
    "prefs.codegen.target = 'cython'\n",
    "\n",
    "# Попытка воспроизведения звуков в jupyter-notebook\n",
    "try:\n",
    "    import IPython.display as ipd\n",
    "    from IPython.display import display\n",
    "    in_notebook = True\n",
    "except ImportError:\n",
    "    in_notebook = False\n",
    "\n",
    "################################################################################\n",
    "# ПАРАМЕТРЫ СЕТИ И ОБУЧЕНИЯ (без эпох)\n",
    "################################################################################\n",
    "\n",
    "num_samples = 50\n",
    "num_samples_partial = 3  # Число примеров, для которых мониторим детальную активность\n",
    "\n",
    "tau = 10*ms\n",
    "dt = 1*ms\n",
    "defaultclock.dt = dt\n",
    "\n",
    "eta = 1e-3 * Hz     # Скорость обучения\n",
    "decay = 1e-2        # Скорость распада\n",
    "sample_duration_image = 200*ms\n",
    "sample_duration_audio = 500*ms\n",
    "sample_duration = max(sample_duration_image, sample_duration_audio)\n",
    "num_time_steps_per_sample = int(sample_duration / dt)\n",
    "total_duration = num_samples * sample_duration\n",
    "\n",
    "N_hidden = 400  # Увеличенный скрытый слой\n",
    "\n",
    "################################################################################\n",
    "# ФУНКЦИИ ДЛЯ ЗАГРУЗКИ ДАННЫХ\n",
    "################################################################################\n",
    "\n",
    "def load_full_mnist():\n",
    "    df = pd.read_csv('mnist_784.csv')\n",
    "    X = df.iloc[:, 0:784].values / 255.0\n",
    "    y = df.iloc[:, 784].values  \n",
    "    return X, y\n",
    "\n",
    "def load_preprocess_audio(num_samples, target_length=5000):\n",
    "    audio_files = glob.glob('free-spoken-digit-dataset/recordings/*.wav')\n",
    "    np.random.shuffle(audio_files)\n",
    "    selected_files = audio_files[:num_samples]\n",
    "    \n",
    "    X_audio_list = []\n",
    "    sr_list = []\n",
    "    digits_audio = []\n",
    "\n",
    "    for file in selected_files:\n",
    "        base_name = file.split('/')[-1]\n",
    "        digit_str = base_name.split('_')[0]\n",
    "        audio_digit = int(digit_str)\n",
    "        digits_audio.append(audio_digit)\n",
    "        \n",
    "        signal, sr = librosa.load(file, sr=None)\n",
    "        sr_list.append(sr)\n",
    "\n",
    "        if len(signal) > target_length:\n",
    "            signal = signal[:target_length]\n",
    "        else:\n",
    "            signal = np.pad(signal, (0, target_length - len(signal)), 'constant')\n",
    "\n",
    "        signal = (signal - np.min(signal)) / (np.max(signal) - np.min(signal))\n",
    "        X_audio_list.append(signal)\n",
    "    \n",
    "    X_audio = np.array(X_audio_list)\n",
    "    sr = sr_list[0] if sr_list else 22050\n",
    "    \n",
    "    unique_digits = np.unique(digits_audio)\n",
    "    if len(unique_digits) < 2 and num_samples > 1:\n",
    "        raise ValueError(\"Недостаточно разнообразных классов. Увеличьте количество файлов или перезапустите.\")\n",
    "    \n",
    "    return X_audio, sr, digits_audio\n",
    "\n",
    "def match_images_to_audio_digits(X, y, digits_audio, num_samples):\n",
    "    matched_images = []\n",
    "    for d in digits_audio:\n",
    "        indices = np.where(y == d)[0]\n",
    "        if len(indices) == 0:\n",
    "            raise ValueError(f\"Не найдено изображений в MNIST с цифрой {d}\")\n",
    "        idx = np.random.choice(indices)\n",
    "        matched_images.append(X[idx])\n",
    "    matched_images = np.array(matched_images)\n",
    "    return matched_images\n",
    "\n",
    "def prepare_input_data(X_image, X_audio, num_time_steps_per_sample):\n",
    "    num_samples_local = X_image.shape[0]\n",
    "    N_input_image = X_image.shape[1]\n",
    "    N_input_audio = X_audio.shape[1]\n",
    "    \n",
    "    input_image_array = np.zeros((int(total_duration / dt), N_input_image))\n",
    "    input_audio_array = np.zeros((int(total_duration / dt), N_input_audio))\n",
    "    \n",
    "    for i in range(num_samples_local):\n",
    "        start_idx = i * num_time_steps_per_sample\n",
    "        end_idx = (i + 1) * num_time_steps_per_sample\n",
    "        input_image_array[start_idx:end_idx, :] = X_image[i]\n",
    "        input_audio_array[start_idx:end_idx, :] = X_audio[i]\n",
    "    \n",
    "    Image_ext = TimedArray(input_image_array, dt=dt)\n",
    "    Audio_ext = TimedArray(input_audio_array, dt=dt)\n",
    "    \n",
    "    return Image_ext, Audio_ext\n",
    "\n",
    "################################################################################\n",
    "# ЗАГРУЗКА ДАННЫХ\n",
    "################################################################################\n",
    "\n",
    "X_full, y_full = load_full_mnist()\n",
    "X_audio, sr, digits_audio = load_preprocess_audio(num_samples=num_samples, target_length=5000)\n",
    "X_image = match_images_to_audio_digits(X_full, y_full, digits_audio, num_samples=num_samples)\n",
    "Image_ext, Audio_ext = prepare_input_data(X_image, X_audio, num_time_steps_per_sample)\n",
    "\n",
    "N_input_image = 784\n",
    "N_input_audio = X_audio.shape[1]\n",
    "\n",
    "################################################################################\n",
    "# ИНИЦИАЛИЗАЦИЯ СЕТИ\n",
    "################################################################################\n",
    "\n",
    "start_scope()\n",
    "\n",
    "w_input_image_hidden_init = np.random.randn(N_input_image * N_hidden)*0.01\n",
    "w_input_audio_hidden_init = np.random.randn(N_input_audio * N_hidden)*0.01\n",
    "w_hidden_image_input_init = np.random.randn(N_hidden * N_input_image)*0.01\n",
    "w_hidden_audio_input_init = np.random.randn(N_hidden * N_input_audio)*0.01\n",
    "\n",
    "threshold_value = 'v > 0.5'\n",
    "\n",
    "input_image_neurons = NeuronGroup(N_input_image, '''\n",
    "    dv/dt = (-v + V_error) / tau : 1\n",
    "    V_error = Image_ext(t, i) - v + V_feedback : 1\n",
    "    V_feedback : 1\n",
    "    ''',\n",
    "    threshold=threshold_value, reset='v = 0', method='euler')\n",
    "\n",
    "input_audio_neurons = NeuronGroup(N_input_audio, '''\n",
    "    dv/dt = (-v + V_error) / tau : 1\n",
    "    V_error = Audio_ext(t, i) - v + V_feedback : 1\n",
    "    V_feedback : 1\n",
    "    ''',\n",
    "    threshold=threshold_value, reset='v = 0', method='euler')\n",
    "\n",
    "hidden_neurons = NeuronGroup(N_hidden, '''\n",
    "    dv/dt = (-v + V_input_image + V_input_audio) / tau : 1\n",
    "    V_input_image : 1\n",
    "    V_input_audio : 1\n",
    "    ''',\n",
    "    threshold=threshold_value, reset='v = 0', method='euler')\n",
    "\n",
    "syn_input_image_hidden = Synapses(input_image_neurons, hidden_neurons, '''\n",
    "    V_input_image_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_input_image_hidden.connect()\n",
    "syn_input_image_hidden.w = w_input_image_hidden_init \n",
    "\n",
    "syn_input_audio_hidden = Synapses(input_audio_neurons, hidden_neurons, '''\n",
    "    V_input_audio_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_input_audio_hidden.connect()\n",
    "syn_input_audio_hidden.w = w_input_audio_hidden_init\n",
    "\n",
    "syn_hidden_image_input = Synapses(hidden_neurons, input_image_neurons, '''\n",
    "    V_feedback_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_hidden_image_input.connect()\n",
    "syn_hidden_image_input.w = w_hidden_image_input_init\n",
    "\n",
    "syn_hidden_audio_input = Synapses(hidden_neurons, input_audio_neurons, '''\n",
    "    V_feedback_post = w * v_pre : 1 (summed)\n",
    "    dw/dt = eta * (v_post * v_pre - w * decay) : 1 (clock-driven)\n",
    "    ''')\n",
    "syn_hidden_audio_input.connect()\n",
    "syn_hidden_audio_input.w = w_hidden_audio_input_init\n",
    "\n",
    "partial_duration = num_samples_partial * sample_duration\n",
    "remaining_duration = total_duration - partial_duration\n",
    "\n",
    "mon_hidden = StateMonitor(hidden_neurons, 'v', record=True)\n",
    "mon_input_image = StateMonitor(input_image_neurons, 'v', record=True)\n",
    "mon_input_audio = StateMonitor(input_audio_neurons, 'v', record=True)\n",
    "spikes_input_image = SpikeMonitor(input_image_neurons)\n",
    "spikes_input_audio = SpikeMonitor(input_audio_neurons)\n",
    "spikes_hidden = SpikeMonitor(hidden_neurons)\n",
    "\n",
    "################################################################################\n",
    "# ОДНОРАЗОВЫЙ ЗАПУСК СИМУЛЯЦИИ\n",
    "################################################################################\n",
    "\n",
    "print(\"Выполнение симуляции для первых 3 примеров...\")\n",
    "run(partial_duration)\n",
    "\n",
    "mon_input_image.active = False\n",
    "mon_input_audio.active = False\n",
    "spikes_input_image.active = False\n",
    "spikes_input_audio.active = False\n",
    "spikes_hidden.active = False\n",
    "\n",
    "print(\"Выполнение симуляции для оставшихся примеров...\")\n",
    "run(remaining_duration)\n",
    "\n",
    "hidden_data_all = mon_hidden.v[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38f8114-8c33-45a2-b60f-1f8e1b5f152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_reconstruction_image(sample_index):\n",
    "    start_time = sample_index * sample_duration\n",
    "    end_time = (sample_index + 1) * sample_duration\n",
    "    start_idx = int(start_time / dt)\n",
    "    end_idx = int(end_time / dt)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    plt.axis('off')\n",
    "    ims = []\n",
    "    \n",
    "    for t in range(start_idx, end_idx):\n",
    "        reconstructed_img = mon_input_image.v[:, t]\n",
    "        im = plt.imshow(reconstructed_img.reshape(28,28), cmap='gray', animated=True)\n",
    "        ims.append([im])\n",
    "    \n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=300, blit=True, repeat_delay=1000)\n",
    "    ani.save(f'animation_sample{sample_index}.gif')\n",
    "    plt.title(f'Реконструкция образца изображения {sample_index} по времени')\n",
    "    plt.close(fig)\n",
    "    display(HTML(ani.to_jshtml()))\n",
    "\n",
    "def animate_reconstruction_audio(sample_index):\n",
    "    start_time = sample_index * sample_duration\n",
    "    end_time = (sample_index + 1) * sample_duration\n",
    "    start_idx = int(start_time / dt)\n",
    "    end_idx = int(end_time / dt)\n",
    "    \n",
    "    reconstructed_signal = mon_input_audio.v[:, start_idx:end_idx].mean(axis=1)\n",
    "    original_signal = X_audio[sample_index]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(original_signal, label='Original Signal')\n",
    "    plt.plot(reconstructed_signal, label='Reconstructed Signal')\n",
    "    plt.legend()\n",
    "    plt.title(f'Реконструкция аудиообразца {sample_index}')\n",
    "    plt.xlabel('Время')\n",
    "    plt.ylabel('Амплитуда')\n",
    "    plt.show()\n",
    "    \n",
    "    sf.write(f'original_signal_sample{sample_index}.wav', original_signal, sr)\n",
    "    sf.write(f'reconstructed_signal_sample{sample_index}.wav', reconstructed_signal, sr)\n",
    "    \n",
    "    if in_notebook:\n",
    "        print(\"Оригинальный сигнал:\")\n",
    "        display(ipd.Audio(original_signal, rate=sr))\n",
    "        print(\"Реконструированный сигнал:\")\n",
    "        display(ipd.Audio(reconstructed_signal, rate=sr))\n",
    "\n",
    "def plot_spikes(spike_monitor, layer_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(spike_monitor.t/ms, spike_monitor.i, '|')\n",
    "    plt.title(f'Спайковая активность в {layer_name}')\n",
    "    plt.xlabel('Время (мсек)')\n",
    "    plt.ylabel('Индекс нейрона')\n",
    "    plt.show()\n",
    "\n",
    "for idx in range(num_samples_partial):\n",
    "    print(f'\\nАнимационная реконструкция для образца изображения {idx}, цифра: {digits_audio[idx]}')\n",
    "    animate_reconstruction_image(idx)\n",
    "    print(f'\\nАнимационная реконструкция для аудиосэмпла {idx}, цифра: {digits_audio[idx]}')\n",
    "    animate_reconstruction_audio(idx)\n",
    "\n",
    "plot_spikes(spikes_input_image, 'Входной слой с изображениями')\n",
    "plot_spikes(spikes_input_audio, 'Входной аудиовход')\n",
    "plot_spikes(spikes_hidden, 'Скрытый слой')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e284b9-8c4b-4ad1-9f8e-b356e5a4387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# КЛАССИЧЕСКАЯ КЛАССИФИКАЦИЯ MNIST ДЛЯ СРАВНЕНИЯ\n",
    "###############################################################################\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, test_size=0.2, random_state=42)\n",
    "clf_classic = LogisticRegression(max_iter=1000)\n",
    "clf_classic.fit(X_train_full, y_train_full)\n",
    "y_pred_classic = clf_classic.predict(X_test_full)\n",
    "classic_accuracy = accuracy_score(y_test_full, y_pred_classic)\n",
    "\n",
    "###############################################################################\n",
    "# КЛАССИФИКАЦИЯ ПО АКТИВНОСТИ СКРЫТОГО СЛОЯ\n",
    "###############################################################################\n",
    "\n",
    "hidden_activity = []\n",
    "for idx in range(num_samples):\n",
    "    start_idx = idx * num_time_steps_per_sample\n",
    "    end_idx = (idx + 1) * num_time_steps_per_sample\n",
    "    mean_activity = np.mean(mon_hidden.v[:, start_idx:end_idx], axis=1)\n",
    "    hidden_activity.append(mean_activity)\n",
    "\n",
    "hidden_activity = np.array(hidden_activity)\n",
    "y_labels = np.array(digits_audio)\n",
    "\n",
    "print(\"Размер данных до очистки:\", hidden_activity.shape, len(y_labels))\n",
    "print(\"Проверка NaN в hidden_activity:\", np.isnan(hidden_activity).any())\n",
    "print(\"Проверка NaN в y_labels:\", np.isnan(y_labels).any())\n",
    "\n",
    "mask = ~np.isnan(hidden_activity).any(axis=1)\n",
    "hidden_activity_clean = hidden_activity[mask]\n",
    "y_labels_clean = y_labels[mask]\n",
    "\n",
    "# Нормируем данные скрытого слоя для повышения устойчивости классификатора\n",
    "scaler = StandardScaler()\n",
    "hidden_activity_scaled = scaler.fit_transform(hidden_activity_clean)\n",
    "\n",
    "if len(np.unique(y_labels_clean)) > 1:\n",
    "    X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(hidden_activity_scaled, y_labels_clean, test_size=0.5, random_state=42)\n",
    "    clf_hidden = LogisticRegression(max_iter=1000)\n",
    "    clf_hidden.fit(X_train_h, y_train_h)\n",
    "    y_pred_hidden = clf_hidden.predict(X_test_h)\n",
    "    hidden_accuracy = accuracy_score(y_test_h, y_pred_hidden)\n",
    "else:\n",
    "    hidden_accuracy = 0.0\n",
    "\n",
    "###############################################################################\n",
    "# ОЦЕНКА РЕКОНСТРУКЦИИ\n",
    "###############################################################################\n",
    "\n",
    "def evaluate_reconstruction_image(sample_index):\n",
    "    start_time = sample_index * sample_duration\n",
    "    end_time = (sample_index + 1) * sample_duration\n",
    "    start_idx = int(start_time / dt)\n",
    "    end_idx = int(end_time / dt)\n",
    "    original_img = X_image[sample_index]\n",
    "    reconstructed_img = mon_input_image.v[:, end_idx-1]\n",
    "    mse_img = mean_squared_error(original_img, reconstructed_img)\n",
    "    corr_img, _ = pearsonr(original_img, reconstructed_img)\n",
    "    print(f\"Оценка реконструкции изображения для сэмпла {sample_index}: MSE={mse_img}, Корреляция={corr_img}\")\n",
    "\n",
    "def evaluate_reconstruction_audio(sample_index):\n",
    "    start_time = sample_index * sample_duration\n",
    "    end_time = (sample_index + 1) * sample_duration\n",
    "    start_idx = int(start_time / dt)\n",
    "    end_idx = int(end_time / dt)\n",
    "    original_signal = X_audio[sample_index]\n",
    "    reconstructed_signal = mon_input_audio.v[:, start_idx:end_idx].mean(axis=1)\n",
    "    mse_audio = mean_squared_error(original_signal, reconstructed_signal)\n",
    "    corr_audio, _ = pearsonr(original_signal, reconstructed_signal)\n",
    "    print(f\"Оценка реконструкции аудио для сэмпла {sample_index}: MSE={mse_audio}, Корреляция={corr_audio}\")\n",
    "\n",
    "for idx in range(num_samples_partial):\n",
    "    evaluate_reconstruction_image(idx)\n",
    "    evaluate_reconstruction_audio(idx)\n",
    "\n",
    "###############################################################################\n",
    "# ИТОГОВЫЕ РЕЗУЛЬТАТЫ\n",
    "###############################################################################\n",
    "\n",
    "print(\"----- Итоговые результаты -----\")\n",
    "print(\"Классический метод (логистическая регрессия по пикселям MNIST):\", classic_accuracy)\n",
    "print(\"Спайковая модель (логрега по скрытому слою):\", hidden_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1632db33-3ace-4e64-aecd-87656b62eb40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
